{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Neural Network from scratch with Tensorflow\n",
    "\n",
    "I am doing this to practice working with data in Tensorflow. I will only use basic Tensorflow ops and structures. For example, I know that tf.nn.softmax will do the softmax computation for me, but I am implementing it myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "# make sure tensorflow version >= 2.9.x for compatability\n",
    "print(tf.__version__)\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "NUM_TRAIN_EXAMPLES = train_X.shape[0]\n",
    "print(f'{NUM_TRAIN_EXAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST images have size 784.0, 28x28\n"
     ]
    }
   ],
   "source": [
    "# analyze some data\n",
    "image_size = tf.constant(train_X[0].size, dtype=tf.float16)\n",
    "image_side_length = tf.cast(tf.sqrt(image_size), tf.int32)\n",
    "print(f\"MNIST images have size {image_size.numpy()}, {image_side_length}x{image_side_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# since its going into a regular NN, we have to reshape it to 784\n",
    "train_X = tf.reshape(train_X, (train_X.shape[0], 784))\n",
    "\n",
    "# change to floats\n",
    "train_X = tf.cast(train_X, tf.float32)\n",
    "train_y = tf.cast(train_y, tf.float32)\n",
    "\n",
    "# now create dataset\n",
    "train_set = tf.data.Dataset.from_tensor_slices((train_X, train_y)).batch(32)\n",
    "print(train_set.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return tf.math.maximum(tf.constant(0, dtype=tf.float32), x)\n",
    "\n",
    "# derivative of the ReLU for backprop\n",
    "def dReLU(x):\n",
    "    x = x.numpy() # convert to np arr for list indexing\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def softmax(z):\n",
    "    return tf.math.divide(tf.math.exp(z), tf.math.reduce_sum(tf.math.exp(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for reference, this is what the ReLU looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xcoord = []\n",
    "ycoord = []\n",
    "\n",
    "for x in range(-100, 100):\n",
    "    y = ReLU(x)\n",
    "    xcoord.append(x)\n",
    "    ycoord.append(y)\n",
    "\n",
    "plt.plot(xcoord, ycoord)\n",
    "plt.title(\"Rectified Linear Unit (ReLU) Activation Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ycoord \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mdReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     xcoord\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m      7\u001b[0m     ycoord\u001b[38;5;241m.\u001b[39mappend(y)\n",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m, in \u001b[0;36mdReLU\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdReLU\u001b[39m(x):\n\u001b[1;32m      6\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# convert to np arr for list indexing\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m     x[x\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int32' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "xcoord = []\n",
    "ycoord = []\n",
    "\n",
    "for x in range(-100, 100):\n",
    "    y = dReLU(tf.constant(x))\n",
    "    xcoord.append(x)\n",
    "    ycoord.append(y)\n",
    "\n",
    "\n",
    "plt.plot(xcoord, ycoord)\n",
    "plt.title(\"Rectified Linear Unit (ReLU) Activation Function DERIVATIVE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss is the more general form of the binary classification formula\n",
    "def cross_entropy_loss(actual, true): # both (batch_size, 10)\n",
    "    \n",
    "    # pred and actual are probablilty distributions for the 10 classes\n",
    "    # e.g. [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] for the actual\n",
    "    # maybe [.73, .2302, ...] for pred\n",
    "    loss = -tf.math.reduce_sum(tf.math.multiply(actual, tf.math.log(pred)))\n",
    "\n",
    "    # normalize by number of samples\n",
    "    return tf.math.subtract(loss, actual.numpy().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_neurons, eps=.1):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.eps = eps\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.delta = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # remember shapes are usually ordered like this:\n",
    "        # (batch_size, width, height, features)\n",
    "        num_inputs = input_shape[-1]\n",
    "        # note: num_inputs is number of outputs in previous layer\n",
    "        # so if previous layer has 10 neurons, num_inputs will be 10\n",
    "        # if previous layer is input layer, num_inputs will be 784 (in MNIST case)\n",
    "        self.w = tf.random.uniform((self.num_neurons, num_inputs), minval=-self.eps, maxval=self.eps, dtype=tf.float32)\n",
    "        self.b = tf.random.uniform((self.num_neurons, ), minval=-self.eps, maxval=self.eps, dtype=tf.float32)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, tf.transpose(self.w)) + self.b\n",
    "\n",
    "class DenseNeuralNet(tf.keras.Model):\n",
    "    # remember to use activaton function between layers\n",
    "    def __init__(self, num_hidden_layers, layer_neurons, learning_rate=.01):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        # TODO: setup loss and accuracy\n",
    "        self.loss_history = []\n",
    "        \n",
    "        # setup layers\n",
    "        self._layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            num_neurons_in_layer = layer_neurons[i]\n",
    "            self._layers.append(FCLayer(num_neurons_in_layer))\n",
    "        \n",
    "        softmax_clf = FCLayer(10)\n",
    "        self._layers.append(softmax_clf)\n",
    "        \n",
    "    \n",
    "    # overrides the fit() method\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        # feed forward (basically calls the call method)\n",
    "        y_pred = self(x) # (batch_size, 10)\n",
    "        # backprop\n",
    "        # update layer weights and biases while traversing backwards\n",
    "        \n",
    "        # one hot encode y\n",
    "        y = tf.one_hot(tf.cast(y, tf.int32), 10)\n",
    "        \n",
    "        # do last layer\n",
    "        delta = y_pred - y\n",
    "        prev_out = self._layers[-2].a\n",
    "        self._layers[-1].delta = delta\n",
    "        self._layers[-1].w -= self.learning_rate * tf.matmul(tf.transpose(prev_out), delta)\n",
    "        \n",
    "        # from layer N-1 to layer 1\n",
    "        for i in range(len(self._layers)-2, 0, -1):\n",
    "            layer = self._layers[i]\n",
    "            w = layer.w\n",
    "            b = layer.b\n",
    "            z = layer.z\n",
    "            a = layer.a\n",
    "            \n",
    "            # the previous layer is the layer L+1 when working from right to left\n",
    "            prev_delta = self._layers[i+1].delta\n",
    "            \n",
    "    \n",
    "            delta = tf.matmul(w, prev_delta) * dReLU(a)\n",
    "            # update rule for vanilla online gradient descent\n",
    "            # w[i,j] -= gamma * o[i] * delta[j]\n",
    "            # bias[j] -= gamma_bias * 1 * delta[j]\n",
    "            w_grad = tf.matmul(tf.transpose(a), delta)\n",
    "            b_grad = delta\n",
    "            \n",
    "            # This is the \"learning\" step\n",
    "            w = w - self.learning_rate * w_grad\n",
    "            b = b - self.learning_rate * b_grad\n",
    "            \n",
    "            layers[i].w = w\n",
    "            layers[i].b = b\n",
    "        \n",
    "        loss = cross_entropy_loss(y, y_pred)\n",
    "        self.loss_history.append(loss)\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def call(self, inputs): # (batch_size, 784)\n",
    "        # feed forward\n",
    "        x = self._layers[0](inputs)\n",
    "        for layer in self._layers[1:-1]:\n",
    "            x = layer(x) # propogate - z\n",
    "            layer.z = x\n",
    "            x = ReLU(x) # activate - a\n",
    "            layer.a = x\n",
    "        \n",
    "        softmax_clf = self._layers[-1]\n",
    "        x = softmax_clf(x) # (batch_size, 10)\n",
    "        return softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] mismatch In[1] shape: 15 vs. 32: [32,15] [32,10] 0 0 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_set): \u001b[38;5;66;03m# X and y are a batch\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss at step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [13], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(X, y):\n\u001b[0;32m---> 12\u001b[0m     metrics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn [12], line 56\u001b[0m, in \u001b[0;36mDenseNeuralNet.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m prev_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39ma\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdelta \u001b[38;5;241m=\u001b[39m delta\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# from layer N-1 to layer 1\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] mismatch In[1] shape: 15 vs. 32: [32,15] [32,10] 0 0 [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = DenseNeuralNet(num_hidden_layers=3, layer_neurons=[25, 20, 15])\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(32, 784), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(32, ), dtype=tf.float32)\n",
    "]\n",
    "\n",
    "\n",
    "# @tf.function(input_signature=train_step_signature)\n",
    "def train_step(X, y):\n",
    "    metrics_dict = model.train_step([X, y])\n",
    "    loss = metrics_dict[\"loss\"]\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    # Train step\n",
    "    for step, (X, y) in enumerate(train_set): # X and y are a batch\n",
    "        loss = train_step(X, y)\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Train loss at step {step} is {loss:.4f}\")\n",
    "        \n",
    "    tf.print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda]",
   "language": "python",
   "name": "conda-env-miniconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7eafcc8f417ce84711ef43e3ea4a0375aea56eb4ba6451442638b2e997f4235a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
